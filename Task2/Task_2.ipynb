{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a21fdad",
   "metadata": {},
   "source": [
    "# Task 2: Generative Models â€“ Investigating VAE vs. GAN Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0734dcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ATML-PA-1' already exists and is not an empty directory.\n",
      "/kaggle/working/ATML-PA-1/Task2\n"
     ]
    }
   ],
   "source": [
    "!git clone -b atm-11 https://github.com/Zapy67/ATML-PA-1\n",
    "%cd ATML-PA-1/Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f96b48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 25, done.\u001b[K\n",
      "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
      "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
      "remote: Total 19 (delta 11), reused 19 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (19/19), 5.46 MiB | 3.79 MiB/s, done.\n",
      "From https://github.com/Zapy67/ATML-PA-1\n",
      "   dea9c76..f172898  atm-11     -> origin/atm-11\n",
      "Updating dea9c76..f172898\n",
      "Fast-forward\n",
      " Task2/Task_2.ipynb                            | 157 \u001b[32m++++++++++++++++++++++++\u001b[m\u001b[31m--\u001b[m\n",
      " Task2/Training_GAN.py                         |  16 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
      " Task2/Training_VAE.py                         |  40 \u001b[32m++++\u001b[m\u001b[31m---\u001b[m\n",
      " Task2/models/GAN_Generations_adv_128.png      | Bin \u001b[31m83396\u001b[m -> \u001b[32m0\u001b[m bytes\n",
      " Task2/models/GAN_Generations_adv_64.png       | Bin \u001b[31m83164\u001b[m -> \u001b[32m0\u001b[m bytes\n",
      " Task2/models/GAN_Generations_basic_64.png     | Bin \u001b[31m83975\u001b[m -> \u001b[32m0\u001b[m bytes\n",
      " Task2/models/GAN_Training_Losses_adv_128.png  | Bin \u001b[31m79938\u001b[m -> \u001b[32m0\u001b[m bytes\n",
      " Task2/models/GAN_Training_Losses_adv_64.png   | Bin \u001b[31m78708\u001b[m -> \u001b[32m0\u001b[m bytes\n",
      " Task2/models/GAN_Training_Losses_basic_64.png | Bin \u001b[31m75096\u001b[m -> \u001b[32m0\u001b[m bytes\n",
      " Task2/models/GAN_basic_64_weights.pth         | Bin \u001b[31m4504490\u001b[m -> \u001b[32m0\u001b[m bytes\n",
      " Task2/models/gan_128_adv_weights.pth          | Bin \u001b[31m5553003\u001b[m -> \u001b[32m0\u001b[m bytes\n",
      " Task2/models/gan_64_adv_weights.pth           | Bin \u001b[31m4504427\u001b[m -> \u001b[32m0\u001b[m bytes\n",
      " 12 files changed, 183 insertions(+), 30 deletions(-)\n",
      " delete mode 100644 Task2/models/GAN_Generations_adv_128.png\n",
      " delete mode 100644 Task2/models/GAN_Generations_adv_64.png\n",
      " delete mode 100644 Task2/models/GAN_Generations_basic_64.png\n",
      " delete mode 100644 Task2/models/GAN_Training_Losses_adv_128.png\n",
      " delete mode 100644 Task2/models/GAN_Training_Losses_adv_64.png\n",
      " delete mode 100644 Task2/models/GAN_Training_Losses_basic_64.png\n",
      " delete mode 100644 Task2/models/GAN_basic_64_weights.pth\n",
      " delete mode 100644 Task2/models/gan_128_adv_weights.pth\n",
      " delete mode 100644 Task2/models/gan_64_adv_weights.pth\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "257a0d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architectures.py\t\t   Linear_Classifier.py\n",
      "colab_training.ipynb\t\t   models\n",
      "data\t\t\t\t   __pycache__\n",
      "GAN_basic_128_weights.pth\t   readme.md\n",
      "GAN_basic_64_weights.pth\t   requirements.txt\n",
      "GAN_Generations_basic_128.png\t   Task_2.ipynb\n",
      "GAN_Generations_basic_64.png\t   Training_GAN.py\n",
      "GAN_Training_Losses_basic_128.png  Training_VAE.py\n",
      "GAN_Training_Losses_basic_64.png   utils.py\n",
      "kernel-metadata.json\t\t   VAE_Training_Losses_64_kl_anneal_false.png\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b16cfbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torch.optim as optim\n",
    "\n",
    "from architectures import VAE, GAN\n",
    "\n",
    "from Linear_Classifier import inference\n",
    "\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6149d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0fc39",
   "metadata": {},
   "source": [
    "## Training GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b444b",
   "metadata": {},
   "source": [
    "Will be training 4 GANS, differing latent Dims (64 vs 128), and basic vs advanced (Advanced has additional steps in training to ensure stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "182407fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training_GAN import train_model as train_GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2517ef8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Downloading CIFAR-10 ===\n",
      "=== Training GAN ===\n",
      "Model has 1120612 parameters\n",
      "Training on cuda\n",
      "Epochs: 40\n",
      "Epoch [1/40]  D_loss: 1.5887  G_loss: 0.7605\n",
      "Epoch [2/40]  D_loss: 1.4204  G_loss: 0.6986\n",
      "Epoch [3/40]  D_loss: 1.4054  G_loss: 0.6965\n",
      "Epoch [4/40]  D_loss: 1.3993  G_loss: 0.6958\n",
      "Epoch [5/40]  D_loss: 1.3961  G_loss: 0.7007\n",
      "Epoch [6/40]  D_loss: 1.3945  G_loss: 0.7021\n",
      "Epoch [7/40]  D_loss: 1.3934  G_loss: 0.7000\n",
      "Epoch [8/40]  D_loss: 1.3921  G_loss: 0.7003\n",
      "Epoch [9/40]  D_loss: 1.3918  G_loss: 0.7013\n",
      "Epoch [10/40]  D_loss: 1.3917  G_loss: 0.7026\n",
      "Epoch [11/40]  D_loss: 1.3917  G_loss: 0.7014\n",
      "Epoch [12/40]  D_loss: 1.3917  G_loss: 0.7014\n",
      "Epoch [13/40]  D_loss: 1.3913  G_loss: 0.7024\n",
      "Epoch [14/40]  D_loss: 1.3901  G_loss: 0.7013\n",
      "Epoch [15/40]  D_loss: 1.3907  G_loss: 0.7012\n",
      "Epoch [16/40]  D_loss: 1.3900  G_loss: 0.7011\n",
      "Epoch [17/40]  D_loss: 1.3891  G_loss: 0.7017\n",
      "Epoch [18/40]  D_loss: 1.3893  G_loss: 0.7025\n",
      "Epoch [19/40]  D_loss: 1.3884  G_loss: 0.7034\n",
      "Epoch [20/40]  D_loss: 1.3868  G_loss: 0.7055\n",
      "Epoch [21/40]  D_loss: 1.3854  G_loss: 0.7052\n",
      "Epoch [22/40]  D_loss: 1.3838  G_loss: 0.7100\n",
      "Epoch [23/40]  D_loss: 1.3864  G_loss: 0.7064\n",
      "Epoch [24/40]  D_loss: 1.3864  G_loss: 0.7061\n",
      "Epoch [25/40]  D_loss: 1.3846  G_loss: 0.7067\n",
      "Epoch [26/40]  D_loss: 1.3832  G_loss: 0.7094\n",
      "Epoch [27/40]  D_loss: 1.3809  G_loss: 0.7104\n",
      "Epoch [28/40]  D_loss: 1.3808  G_loss: 0.7119\n",
      "Epoch [29/40]  D_loss: 1.3822  G_loss: 0.7115\n",
      "Epoch [30/40]  D_loss: 1.3821  G_loss: 0.7106\n",
      "Epoch [31/40]  D_loss: 1.3834  G_loss: 0.7088\n",
      "Epoch [32/40]  D_loss: 1.3827  G_loss: 0.7082\n",
      "Epoch [33/40]  D_loss: 1.3828  G_loss: 0.7087\n",
      "Epoch [34/40]  D_loss: 1.3834  G_loss: 0.7081\n",
      "Epoch [35/40]  D_loss: 1.3821  G_loss: 0.7077\n",
      "Epoch [36/40]  D_loss: 1.3819  G_loss: 0.7074\n",
      "Epoch [37/40]  D_loss: 1.3814  G_loss: 0.7094\n",
      "Epoch [38/40]  D_loss: 1.3800  G_loss: 0.7099\n",
      "Epoch [39/40]  D_loss: 1.3787  G_loss: 0.7091\n",
      "Epoch [40/40]  D_loss: 1.3778  G_loss: 0.7124\n",
      "=== Plotting Loss Curves ===\n",
      "=== Plotting Generated Samples ===\n"
     ]
    }
   ],
   "source": [
    "train_GAN(64, basic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8aa6daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Downloading CIFAR-10 ===\n",
      "=== Training GAN ===\n",
      "Model has 1382756 parameters\n",
      "Training on cuda\n",
      "Epochs: 40\n",
      "Epoch [1/40]  D_loss: 1.5397  G_loss: 0.8670\n",
      "Epoch [2/40]  D_loss: 1.4230  G_loss: 0.6904\n",
      "Epoch [3/40]  D_loss: 1.4064  G_loss: 0.6973\n",
      "Epoch [4/40]  D_loss: 1.3980  G_loss: 0.7009\n",
      "Epoch [5/40]  D_loss: 1.3963  G_loss: 0.6997\n",
      "Epoch [6/40]  D_loss: 1.3934  G_loss: 0.7004\n",
      "Epoch [7/40]  D_loss: 1.3931  G_loss: 0.7005\n",
      "Epoch [8/40]  D_loss: 1.3928  G_loss: 0.7034\n",
      "Epoch [9/40]  D_loss: 1.3920  G_loss: 0.7033\n",
      "Epoch [10/40]  D_loss: 1.3912  G_loss: 0.7023\n",
      "Epoch [11/40]  D_loss: 1.3912  G_loss: 0.7034\n",
      "Epoch [12/40]  D_loss: 1.3924  G_loss: 0.7037\n",
      "Epoch [13/40]  D_loss: 1.3916  G_loss: 0.7015\n",
      "Epoch [14/40]  D_loss: 1.3917  G_loss: 0.7021\n",
      "Epoch [15/40]  D_loss: 1.3902  G_loss: 0.7022\n",
      "Epoch [16/40]  D_loss: 1.3904  G_loss: 0.7025\n",
      "Epoch [17/40]  D_loss: 1.3893  G_loss: 0.7037\n",
      "Epoch [18/40]  D_loss: 1.3884  G_loss: 0.7031\n",
      "Epoch [19/40]  D_loss: 1.3867  G_loss: 0.7036\n",
      "Epoch [20/40]  D_loss: 1.3847  G_loss: 0.7072\n",
      "Epoch [21/40]  D_loss: 1.3855  G_loss: 0.7074\n",
      "Epoch [22/40]  D_loss: 1.3853  G_loss: 0.7047\n",
      "Epoch [23/40]  D_loss: 1.3845  G_loss: 0.7045\n",
      "Epoch [24/40]  D_loss: 1.3842  G_loss: 0.7047\n",
      "Epoch [25/40]  D_loss: 1.3828  G_loss: 0.7077\n",
      "Epoch [26/40]  D_loss: 1.3840  G_loss: 0.7054\n",
      "Epoch [27/40]  D_loss: 1.3844  G_loss: 0.7048\n",
      "Epoch [28/40]  D_loss: 1.3842  G_loss: 0.7057\n",
      "Epoch [29/40]  D_loss: 1.3840  G_loss: 0.7063\n",
      "Epoch [30/40]  D_loss: 1.3828  G_loss: 0.7079\n",
      "Epoch [31/40]  D_loss: 1.3822  G_loss: 0.7066\n",
      "Epoch [32/40]  D_loss: 1.3823  G_loss: 0.7077\n",
      "Epoch [33/40]  D_loss: 1.3822  G_loss: 0.7077\n",
      "Epoch [34/40]  D_loss: 1.3825  G_loss: 0.7067\n",
      "Epoch [35/40]  D_loss: 1.3834  G_loss: 0.7054\n",
      "Epoch [36/40]  D_loss: 1.3836  G_loss: 0.7049\n",
      "Epoch [37/40]  D_loss: 1.3835  G_loss: 0.7042\n",
      "Epoch [38/40]  D_loss: 1.3822  G_loss: 0.7069\n",
      "Epoch [39/40]  D_loss: 1.3825  G_loss: 0.7061\n",
      "Epoch [40/40]  D_loss: 1.3818  G_loss: 0.7059\n",
      "=== Plotting Loss Curves ===\n",
      "=== Plotting Generated Samples ===\n"
     ]
    }
   ],
   "source": [
    "train_GAN(128, basic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e8009",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_GAN(64, basic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa02392",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_GAN(128, basic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b5046d",
   "metadata": {},
   "source": [
    "## Training VAEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086adcf",
   "metadata": {},
   "source": [
    "Will be training 4 VAEs, with latent dimensions = 64, and 128 respectively, as well as turning KL Annealing On/Off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce03da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training_VAE import train_model as train_VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04dd6732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Downloading CIFAR-10 ===\n",
      "=== Training VAE ===\n",
      "Model has 1506595 parameters\n",
      "Training on cuda\n",
      "Epochs: 50\n",
      "====> Epoch: 1 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 2 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 3 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 4 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 5 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 6 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 7 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 8 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 9 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 10 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 11 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 12 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 13 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 14 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 15 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 16 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 17 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 18 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 19 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 20 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 21 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 22 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 23 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 24 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 25 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 26 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 27 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 28 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: -0.0000)\n",
      "====> Epoch: 29 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 30 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 31 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 32 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 33 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: -0.0000)\n",
      "====> Epoch: 34 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 35 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 36 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 37 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: -0.0000)\n",
      "====> Epoch: 38 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: -0.0000)\n",
      "====> Epoch: 39 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 40 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 41 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 42 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 43 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 44 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 45 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 46 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 47 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 48 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 49 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Epoch: 50 Average loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "====> Test set loss: 0.0010 (Recon: 0.0010, KL: 0.0000)\n",
      "=== Plotting Loss Curves ===\n",
      "=== Plotting Generated Samples And Reconstructions ===\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x128 and 64x2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_853/2103387517.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_VAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_annealing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/kaggle/working/ATML-PA-1/Task2/Training_VAE.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(latent_dim, kl_annealing)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Plotting Generated Samples And Reconstructions ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0mvisualize_gaussian_generations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_annealed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkl_annealed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mvisualise_reconstructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_annealed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkl_annealed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/ATML-PA-1/Task2/Training_VAE.py\u001b[0m in \u001b[0;36mvisualize_gaussian_generations\u001b[0;34m(model, latent_dim, kl_annealed, num_samples)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Reconstructions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;31m# Determine grid size automatically (square-ish)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/ATML-PA-1/Task2/Training_VAE.py\u001b[0m in \u001b[0;36mgenerate_samples\u001b[0;34m(model, num_samples)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/ATML-PA-1/Task2/architectures.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# z [batch, latent_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_fc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_deconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x128 and 64x2048)"
     ]
    }
   ],
   "source": [
    "train_VAE(64, kl_annealing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b78b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_VAE(128, kl_annealing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_VAE(64, kl_annealing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7aa049",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_VAE(128, kl_annealing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
